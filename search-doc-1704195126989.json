{"searchDocs":[{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/flowtide/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/flowtide/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/flowtide/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":"","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/flowtide/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"","version":null},{"title":"CosmosDB Connector","type":0,"sectionRef":"#","url":"/flowtide/docs/connectors/cosmosdb","content":"","keywords":"","version":"Next"},{"title":"Sink​","type":1,"pageTitle":"CosmosDB Connector","url":"/flowtide/docs/connectors/cosmosdb#sink","content":" The CosmosDB sink allows the insertion of data into a CosmosDB container.  info All CosmosDB insertions must contain a column called 'id' and also a column that matches the configured partition key on the CosmosDB container.  Its implementation waits fully until the stream has reached a steady state at a time T until it writes data to the container. This means that its table output can always be traced back to a state from the source systems.  To use the CosmosDB Sink add the following line to the ReadWriteFactory:  factory.AddCosmosDbSink(&quot;your regexp on table names&quot;, connectionString, databaseName, containerName);   ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"CosmosDB Connector","url":"/flowtide/docs/connectors/cosmosdb#example","content":" Having a column named 'id' and also a column matching the configured primary key is required for the sink to function.  sqlBuilder.Sql(@&quot; INSERT into cosmos SELECT userKey as id, companyId as pk, firstName, lastName FROM users &quot;); factory.AddCosmosDbSink(&quot;cosmos&quot;, connectionString, databaseName, containerName); ...  ","version":"Next","tagName":"h3"},{"title":"Elasticsearch Connector","type":0,"sectionRef":"#","url":"/flowtide/docs/connectors/elasticsearch","content":"","keywords":"","version":"Next"},{"title":"Sink​","type":1,"pageTitle":"Elasticsearch Connector","url":"/flowtide/docs/connectors/elasticsearch#sink","content":" The ElasticSearch sink allows insertion into an index.  info All ElasticSearch insertions must contain a column called '_id' this column is the unique identifier in the elasticsearch index. This field will not be added to the source fields.  To use the ElasticSearch Sink add the following line to the ReadWriteFactory:  factory.AddElasticsearchSink(&quot;*&quot;, elasticSearchConnectionSettings);   The table name in the write relation becomes the index the sink writes to.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Elasticsearch Connector","url":"/flowtide/docs/connectors/elasticsearch#example","content":" Having a column named '_id' is required for the sink to function.  sqlBuilder.Sql(@&quot; INSERT into elastic_index_name SELECT userKey as _id, userKey, companyId, firstName, lastName FROM users &quot;); factory.AddElasticsearchSink(&quot;*&quot;, elasticSearchConnectionSettings); ...   ","version":"Next","tagName":"h3"},{"title":"Set alias on initial data completion​","type":1,"pageTitle":"Elasticsearch Connector","url":"/flowtide/docs/connectors/elasticsearch#set-alias-on-initial-data-completion","content":" One way to integrate with elasticsearch is to create a new index for each new stream version and change an alias to point to the new index. This is possible by using the GetIndexNameFunc and OnInitialDataSent functions in the options.  Example:  factory.AddElasticsearchSink(&quot;*&quot;, new FlowtideDotNet.Connector.ElasticSearch.FlowtideElasticsearchOptions() { ConnectionSettings = connectionSettings, CustomMappings = (props) =&gt; { // Add cusotm mappings }, GetIndexNameFunc = (writeRelation) =&gt; { // Set an index name that will be unique for this run // The index name must be possible to be recovered between crashes to write to the same index return $&quot;{writeRelation.NamedObject.DotSeperated}-{tagVersion}&quot;; }, OnInitialDataSent = async (client, writeRelation, indexName) =&gt; { var aliasName = writeRelation.NamedObject.DotSeperated; // Get indices that the alias already points to. var oldIndices = await client.GetIndicesPointingToAliasAsync(aliasName); // Add the index to the alias var putAliasResponse = await client.Indices.PutAliasAsync(indexName, aliasName); if (putAliasResponse.IsValid) { // Remove all old indices that existed on the alias foreach (var oldIndex in oldIndices) { await client.Indices.DeleteAsync(oldIndex); } } else { throw new InvalidOperationException(putAliasResponse.ServerError.Error.StackTrace); } }, });  ","version":"Next","tagName":"h3"},{"title":"Kafka Connector","type":0,"sectionRef":"#","url":"/flowtide/docs/connectors/kafka","content":"","keywords":"","version":"Next"},{"title":"Source​","type":1,"pageTitle":"Kafka Connector","url":"/flowtide/docs/connectors/kafka#source","content":" The Kafka Source allows a stream to fetch data from a kafka stream as a table in a stream.  The source is added to the read write factory with the following line:  factory.AddKafkaSource(&quot;your regexp on table names&quot;, new FlowtideKafkaSourceOptions() { ConsumerConfig = kafkaConsumerConfig, KeyDeserializer = keyDeserializer, ValueDeserializer = valueDeserializer });   The table name in the read relation becomes the topic name the source will read from.  The following key deserializers exist:  FlowtideKafkaJsonKeyDeserializer - deserializes a json keyFlowtidekafkaStringKeyDeserializer - deserializes a string key  The following value deserializers exist:  FlowtideKafkaUpsertJsonDeserializer - Deserializes the value as json, if the value is not null, its an upsert, if it is null, its a delete.  The source has a special column name for the key, it is called _key which can be used to select the key value from a kafka message.  ","version":"Next","tagName":"h2"},{"title":"Usage in SQL​","type":1,"pageTitle":"Kafka Connector","url":"/flowtide/docs/connectors/kafka#usage-in-sql","content":" CREATE TABLE my_kafka_topic ( _key, firstName, lastName ); INSERT INTO outputtable SELECT _key, firstName, lastName FROM my_kafka_topic;   ","version":"Next","tagName":"h3"},{"title":"Sink​","type":1,"pageTitle":"Kafka Connector","url":"/flowtide/docs/connectors/kafka#sink","content":" The kafka sink allows a stream to write events to kafka.  The sink is added to the read write factory with the following line:  factory.AddKafkaSink(&quot;your regexp on table names&quot;, new FlowtideKafkaSinkOptions() { KeySerializer = new FlowtideKafkaStringKeySerializer(), ProducerConfig = config, ValueSerializer = new FlowtideKafkaUpsertJsonSerializer() });   Same as the source, it writes to the topic name that is entered in the write relation.  Available key serializers:  FlowtideKafkaJsonKeySerializer - JSON serializes the key valueFlowtideKafkaStringKeySerializer - Outputs a string value, only works if the key is in a string type.  Available value serializers:  FlowtideKafkaUpsertJsonSerializer - Outputs the value as json, if it is a delete, it outputs null as the value.  ","version":"Next","tagName":"h2"},{"title":"Extend event processing logic​","type":1,"pageTitle":"Kafka Connector","url":"/flowtide/docs/connectors/kafka#extend-event-processing-logic","content":" There are two properties in the options that can help add extra logic to the kafka sink.  EventProcessor - Called on all events that will be sent to kafka.OnInitialDataSent - Called once on a new stream when the first data has been sent (usually after the first checkpoint).  These functions can help implement logic such as having an external state store for a kafka topic that keeps track of all the data that has been sent to the topic. If a stream is modified and republished and has to start from the beginning, this state store can then make sure only delta valeus are sent to the kafka topic, and deletions of events that no longer exists.  Example:  factory.AddKafkaSink(&quot;your regexp on table names&quot;, new FlowtideKafkaSinkOptions() { ... EventProcessor = async (events) =&gt; { for (int i = 0; i &lt; events.Count; i++) { // Check if the event exists with the exact key and value in the store var exists = await dbLookup.ExistAsync(events[i].Key, events[i].Value); if (exists) { events.RemoveAt(i); i--; } // Add the data with a run version that should be unique of this stream version. await dbLookup.Add(events[i].Key, events[i].Value, runVersion); } }, OnInitialDataSent = (producer, writeRelation, topicName) =&gt; { // Get all events that does not have the latest run version await foreach (var e in dbLookup.GetEventsNotMatchingVersion(runVersion)) { // Send delete on all events that no longer exist await producer.SendAsync(new Message&lt;byte[], byte[]?&gt;() { Key = e.Key, Value = null }); } // Delete the events from the state store. await dbLookup.DeleteNotMatchingVersion(runVersion); } });  ","version":"Next","tagName":"h3"},{"title":"MongoDB Connector","type":0,"sectionRef":"#","url":"/flowtide/docs/connectors/mongodb","content":"","keywords":"","version":"Next"},{"title":"Sink​","type":1,"pageTitle":"MongoDB Connector","url":"/flowtide/docs/connectors/mongodb#sink","content":" The MongoDB sink allows the insertion of data into a MongoDB collection.  The nuget package for the connector is:  FlowtideDotNet.Connector.MongoDB  Its implementation waits fully until the stream has reached a steady state at a time T until it writes data to the collection. This means that its table output can always be traced back to a state from the source systems.  To use the MongoDB Sink add the following line to the ReadWriteFactory:  factory.AddMongoDbSink(&quot;regex pattern for tablename&quot;, new FlowtideMongoDBSinkOptions() { Collection = collection, //MongoDB collection Database = databaseName, // MongoDB database ConnectionString = connectionString, //Connection string to MongoDB PrimaryKeys = primaryKeys //List of columns that will be treated as primary keys in the collection });   ","version":"Next","tagName":"h2"},{"title":"Overwriting data in a collection and cleaning up old data​","type":1,"pageTitle":"MongoDB Connector","url":"/flowtide/docs/connectors/mongodb#overwriting-data-in-a-collection-and-cleaning-up-old-data","content":" It is possible with the MongoDB sink to append metadata to documents and remove data from previous runs. This can be helpful when the stream is changed and you want to write to the same collection, but remove data from a previous run.  To do this we add the following code:  factory.AddMongoDbSink(&quot;regex pattern for tablename&quot;, new FlowtideMongoDBSinkOptions() { ... TransformDocument = (doc) =&gt; { // version should come from configuration doc.Add(&quot;_metadata&quot;, run_version); }, OnInitialDataSent = async (collection) =&gt; { await collection.DeleteManyAsync(Builders&lt;BsonDocument&gt;.Filter.Not(Builders&lt;BsonDocument&gt;.Filter.Eq(&quot;_metadata&quot;, run_version))); } });   This will append a metadata field to all documents with the current run version. When the initial data from the stream has been saved, it will delete all documents that does not have the metadata information.  ","version":"Next","tagName":"h3"},{"title":"Watermark updates​","type":1,"pageTitle":"MongoDB Connector","url":"/flowtide/docs/connectors/mongodb#watermark-updates","content":" It is possible to listen to watermark updates, this is done by setting the OnWatermarkUpdate property in the options.  Example:  factory.AddMongoDbSink(&quot;regex pattern for tablename&quot;, new FlowtideMongoDBSinkOptions() { ... OnWatermarkUpdate = async (watermark) =&gt; { // Inform other systems for instance about the watermark change. } });  ","version":"Next","tagName":"h3"},{"title":"Arithmetic Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic","content":"","keywords":"","version":"Next"},{"title":"Sum​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#sum","content":" Substrait definition  Calculates the sum of numeric values, if there are no rows a NULL value is returned. if a value is non numeric such as a string or null, those values are ignored.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#sql-usage","content":" SELECT sum(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Sum0​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#sum0","content":" Substrait definition  Calculates the sum of numeric values, if there are no rows a 0 value is returned. if a value is non numeric such as a string or null, those values are ignored.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#sql-usage-1","content":" SELECT sum0(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Min​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#min","content":" Substrait definition  Returns the minimum value in the result. If there are no rows a NULL value is returned. MIN ignores any null input values.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/arithmetic#sql-usage-2","content":" SELECT min(column1) FROM ...  ","version":"Next","tagName":"h3"},{"title":"List Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/aggregatefunctions/list","content":"","keywords":"","version":"Next"},{"title":"List Agg​","type":1,"pageTitle":"List Functions","url":"/flowtide/docs/expressions/aggregatefunctions/list#list-agg","content":" This function does not have a substrait definition.  List Agg creates a list of values per group. This is useful when denormalizing data. It takes in one expression which will be the value added to the list for that row.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"List Functions","url":"/flowtide/docs/expressions/aggregatefunctions/list#sql-usage","content":" SELECT key1, list_agg(value1) FROM table1 GROUP BY key1   Given the following two rows:  1, 'hello' 1, 'world'  The output would be:  1, ['hello', 'world'] ","version":"Next","tagName":"h3"},{"title":"Generic Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/aggregatefunctions/generic","content":"","keywords":"","version":"Next"},{"title":"Count​","type":1,"pageTitle":"Generic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/generic#count","content":" Substrait definition  Counts all rows in a query. This function takes no parameters, the implementation of count with a column name is not yet implemented.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Generic Functions","url":"/flowtide/docs/expressions/aggregatefunctions/generic#sql-usage","content":" SELECT count(*) FROM ...  ","version":"Next","tagName":"h3"},{"title":"SQL Server Connector","type":0,"sectionRef":"#","url":"/flowtide/docs/connectors/sqlserver","content":"","keywords":"","version":"Next"},{"title":"Supported Data Types​","type":1,"pageTitle":"SQL Server Connector","url":"/flowtide/docs/connectors/sqlserver#supported-data-types","content":" The SQL Server connector supports reading and writing the following data types:  IntBigIntBinaryBitCharDateDatetimeDatetime2DecimalFloatImageMoneyNcharNtextNumericNvarcharRealSmalldatetimeSmallintTextTimeTinyintUniqueidentifierVarbinaryVarcharXml  ","version":"Next","tagName":"h2"},{"title":"Source​","type":1,"pageTitle":"SQL Server Connector","url":"/flowtide/docs/connectors/sqlserver#source","content":" The SQL Server Source allows Flowtide to fetch rows and updates from a SQL Server table. There is one prerequisite for this connector to work:  info Change tracking must be enabled on the table.  Without change tracking, Flowtide wont be able to find updates on the table. There are plans to allow the source to run in batch mode where it computes the delta inside of the connector, but that is not yet available.  The SQL Server Source can be added to the 'ReadWriteFactory' with the following line:  factory.AddSqlServerSource(&quot;your regexp on table names&quot;, () =&gt; connectionString);   The connection string must be set as a function, since the idea is that the connection string might change, from say a system such asHashicorp Vault.  The source uses the following logic to fetch data into the stream:    The source will retry fetching data in-case of a SQL Server error, as long as it can reconnect to the database. It will mark the operator as unhealthy, but it will not trigger a stream restart.  If the operator cannot reconnect to the SQL Server, it will trigger a full stream restart.  ","version":"Next","tagName":"h2"},{"title":"Sink​","type":1,"pageTitle":"SQL Server Connector","url":"/flowtide/docs/connectors/sqlserver#sink","content":" The SQL Server Sink implements the grouped write operator. This means that all rows are grouped by a primary key, thus all sink tables must have a primary key defined.  info All SQL Server Sink tables must have a primary key defined. The primary key must also be in the query that fills the table.  Its implementation waits fully until the stream has reached a steady state at a time T until it writes data to the database. This means that its table output can always be traced back to a state from the source systems.  To use the SQL Server Sink add the following line to the ReadWriteFactory:  factory.AddSqlServerSink(&quot;your regexp on table names&quot;, () =&gt; connectionString);   As with the SQL Server Source, the connection string is returned by a function to enable dynamic connection strings.  The sink inserts data into SQL Server by creating a temporary table, which follows the table structure of the destination with an added operation metadata column. The data is inserted into the temporary table using Bulk Copy. This allows for fast binary insertion into the temporary table.  After data has been inserted into the temporary table, a merge into statement is run that merges data into the destination table. After all data has been merged, the temporary table is cleared of all data.  warning If there are multiple rows in the result with the same primary key, only the latest seen row will be inserted into the destination table.  ","version":"Next","tagName":"h2"},{"title":"SQL Table Provider​","type":1,"pageTitle":"SQL Server Connector","url":"/flowtide/docs/connectors/sqlserver#sql-table-provider","content":" The SQL table provider is added to the SQL plan builder which will try and look after used tables in its configured SQL Server. It provides metadata information about what the column names are in the table.  To use the table provider add the following line to the Sql plan builder:  sqlBuilder.AddSqlServerProvider(() =&gt; connectionString);  ","version":"Next","tagName":"h2"},{"title":"Boolean Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/boolean","content":"","keywords":"","version":"Next"},{"title":"Or​","type":1,"pageTitle":"Boolean Functions","url":"/flowtide/docs/expressions/scalarfunctions/boolean#or","content":" Substrait definition  Or implements the boolean logic Or operator. Its return value will always be a boolean. An argument into the Or function that is not a boolean will be the same as the boolean value false.  Implements Kleene logic with the following truth table:  +------+-------+-----+-----+-----+ | | **B** | + **A OR B** +-----+-----+-----+ | |**F**|**N**|**T**| +------+-------+-----+-----+-----+ | | **F** | F | N | T | + +-------+-----+-----+-----+ |**A** | **N** | N | N | T | + +-------+-----+-----+-----+ | | **T** | T | T | T | +------+-------+-----+-----+-----+   F = False, T = True, N = Null  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Boolean Functions","url":"/flowtide/docs/expressions/scalarfunctions/boolean#sql-usage","content":" ... WHERE c1 = 'hello' OR c2 = 'world'   ","version":"Next","tagName":"h3"},{"title":"And​","type":1,"pageTitle":"Boolean Functions","url":"/flowtide/docs/expressions/scalarfunctions/boolean#and","content":" Substrait definition  And implements the boolean logic And operator. Its return value will always be a boolean. An argument into the And function that is not a boolean will be the same as the boolean value false.  Implements Kleene logic with the following truth table:  +------+-------+-----+-----+-----+ | | **B** | + **A AND B** +-----+-----+-----+ | |**F**|**N**|**T**| +------+-------+-----+-----+-----+ | | **F** | F | F | F | + +-------+-----+-----+-----+ |**A** | **N** | F | N | N | + +-------+-----+-----+-----+ | | **T** | F | N | T | +------+-------+-----+-----+-----+   F = False, T = True, N = Null  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Boolean Functions","url":"/flowtide/docs/expressions/scalarfunctions/boolean#sql-usage-1","content":" ... WHERE c1 = 'hello' AND c2 = 'world'  ","version":"Next","tagName":"h3"},{"title":"Datetime Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/datetime","content":"","keywords":"","version":"Next"},{"title":"Strftime​","type":1,"pageTitle":"Datetime Functions","url":"/flowtide/docs/expressions/scalarfunctions/datetime#strftime","content":" Substrait definition  Converts a timestamp in microseconds since 1970-01-01 00:00:00.000000 to a string. See strftime on how to to write the format string.  Arguments:  Timestamp in microsecondsFormat as a string  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Datetime Functions","url":"/flowtide/docs/expressions/scalarfunctions/datetime#sql-usage","content":" INSERT INTO output SELECT strftime(Orderdate, '%Y-%m-%d %H:%M:%S') as Orderdate FROM Orders   ","version":"Next","tagName":"h3"},{"title":"Get timestamp​","type":1,"pageTitle":"Datetime Functions","url":"/flowtide/docs/expressions/scalarfunctions/datetime#get-timestamp","content":" This function has no substrait equivalent  warning Get timestamp is not yet supported inside of join conditions.  info If you do comparisons with gettimestamp it may be benificial to use buffered views to only send out changed rows to the rest of the stream. Please see Buffered view.  Get the current timestamp (current datetime).  This is a meta function that itself does no computation, but is instead replaced during the optimization step with joins against a timestamp data source.  Example:    Where if project uses gettimestamp becomes:    This means that all rows that are evaluated will have the same value of gettimestamp to ensure consistent results.  The timestamp provider also publishes a watermark called '__timestamp' which can be used to see the current time that has been evaluted in the stream.  By default the timestamp is updated every hour. This is configurable during the stream setup:  streamBuilder .SetGetTimestampUpdateInterval(TimeSpan.FromHours(12))   ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Datetime Functions","url":"/flowtide/docs/expressions/scalarfunctions/datetime#sql-usage-1","content":" INSERT INTO output SELECT gettimestamp() as CurrentDateTime FROM Orders  ","version":"Next","tagName":"h3"},{"title":"Comparison Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/comparison","content":"","keywords":"","version":"Next"},{"title":"Equal​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#equal","content":" Substrait definition  Compares equality of two values. If the two values have different types they are not considered equal, so a float with value 1 will not equal an integer with value 1. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage","content":" ... WHERE c1 = 'hello'   ","version":"Next","tagName":"h3"},{"title":"Not equal​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#not-equal","content":" Substrait definition  Checks two values for non equality. Different types will immedietly return true, that the values are not equal. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-1","content":" ... WHERE c1 != 'hello'   ","version":"Next","tagName":"h3"},{"title":"Greater than​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#greater-than","content":" Substrait definition  Checks if the left value is greater than the right value. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-2","content":" ... WHERE c1 &gt; 1   ","version":"Next","tagName":"h3"},{"title":"Greater than or equal​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#greater-than-or-equal","content":" Substrait definition  Checks if the left value is greater than or equal to the right value. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-3","content":" ... WHERE c1 &gt;= 1   ","version":"Next","tagName":"h3"},{"title":"Less than​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#less-than","content":" Substrait definition  Checks if the left value is less than the right value. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-4","content":" ... WHERE c1 &lt; 1   ","version":"Next","tagName":"h3"},{"title":"Less than or equal​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#less-than-or-equal","content":" Substrait definition  Checks if the left value is less than or equal to the right value. If any argument is null, the result is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-5","content":" ... WHERE c1 &lt;= 1   ","version":"Next","tagName":"h3"},{"title":"Between​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#between","content":" Substrait definition  Checks if an expression is between two values.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-6","content":" ... WHERE c1 BETWEEN 100 AND 200   ","version":"Next","tagName":"h3"},{"title":"Is not null​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#is-not-null","content":" Substrait definition  Checks if a single argument is not equal to null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-7","content":" ... WHERE c1 is not null   ","version":"Next","tagName":"h3"},{"title":"Is Null​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#is-null","content":" Substrait definition  Checks if a signle argument is null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-8","content":" ... WHERE c1 is null   ","version":"Next","tagName":"h3"},{"title":"Coalesce​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#coalesce","content":" Substrait definition  Returns the first value, left to right that is not equal to null. If all values are null, a null value is returned.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-9","content":" SELECT coalesce(column1, column2) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Is Infinite​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#is-infinite","content":" Substrait definition  Checks if a numeric value is positive or negative infinite. If the value is NaN (0 / 0), or another type, it returns false.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-10","content":" SELECT is_infinite(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Is Finite​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#is-finite","content":" Substrait definition  Checks if a numeric value is not positive or negative infinite or NaN. If the value is not numeric it returns false.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-11","content":" SELECT is_finite(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Is NaN​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#is-nan","content":" Substrait definition  Checks if an exprssion is not a numeric value. A null value returns null as in the substrait definition.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Comparison Functions","url":"/flowtide/docs/expressions/scalarfunctions/comparison#sql-usage-12","content":" SELECT is_nan(column1) FROM ...  ","version":"Next","tagName":"h3"},{"title":"Arithmetic Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic","content":"","keywords":"","version":"Next"},{"title":"Add​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#add","content":" Substrait definition  Add takes two parameters and does an addition of the two values.  Add depends on the input types on what result it will give:  Left type\tRight type\tOutputInteger\tInteger\tInteger Integer\tFloat\tFloat Float\tFloat\tFloat Non numeric\tInteger\tNull num numeric\tFloat\tNull Non numeric\tNon numeric\tNull  Only numeric inputs will return a result, otherwise it will return null.  ","version":"Next","tagName":"h2"},{"title":"SQL usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#sql-usage","content":" In SQL the add function is called using the plus operator:  SELECT column1 + 13 FROM ...   ","version":"Next","tagName":"h3"},{"title":"Subtract​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#subtract","content":" Substrait definition  Subtract takes two parameters and does a subtraction of the two values.  Subtract depends on the input types on what result it will give:  Left type\tRight type\tOutputInteger\tInteger\tInteger Integer\tFloat\tFloat Float\tFloat\tFloat Non numeric\tInteger\tNull num numeric\tFloat\tNull Non numeric\tNon numeric\tNull  Only numeric inputs will return a result, otherwise it will return null.  ","version":"Next","tagName":"h2"},{"title":"SQL usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#sql-usage-1","content":" In SQL the subtract function is called using the minus operator:  SELECT column1 - 13 FROM ...   ","version":"Next","tagName":"h3"},{"title":"Multiply​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#multiply","content":" Substrait definition  Multipies two numbers.  Multiply depends on the input types on what result it will give:  Left type\tRight type\tOutputInteger\tInteger\tInteger Integer\tFloat\tFloat Float\tFloat\tFloat Non numeric\tInteger\tNull num numeric\tFloat\tNull Non numeric\tNon numeric\tNull  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#sql-usage-2","content":" SELECT column1 * 3 FROM ...   ","version":"Next","tagName":"h3"},{"title":"Divide​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#divide","content":" Substrait definition  Divide two numbers.  Divide depends on the input types on what result it will give:  Left type\tRight type\tOutputInteger\tInteger\tFloat Integer\tFloat\tFloat Float\tFloat\tFloat Non numeric\tInteger\tNull num numeric\tFloat\tNull Non numeric\tNon numeric\tNull  There are some special cases when dividing with zero:  0 / 0 -&gt; this results in NaN.PositiveNumber / 0 -&gt; +InfinityNegativeNumber / 0 -&gt; -Infinity  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#sql-usage-3","content":" SELECT column1 / 3 FROM ...   ","version":"Next","tagName":"h3"},{"title":"Negate​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#negate","content":" Substrait definition  Negates a numeric value, example:  1 becomes -1-1 becomes 11.3 becomes -1.3  Non numeric values becomes 'null'.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Arithmetic Functions","url":"/flowtide/docs/expressions/scalarfunctions/arithmetic#sql-usage-4","content":" SELECT -column1 FROM ...  ","version":"Next","tagName":"h3"},{"title":"Rounding Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/rounding","content":"","keywords":"","version":"Next"},{"title":"Ceiling​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#ceiling","content":" Substrait definition  Rounds a number up to its closest integer.  Its output type will always be an integer, if a non numeric type is passed in, the function will return null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#sql-usage","content":" SELECT ceiling(column1) FROM ...   or  SELECT ceil(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Floor​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#floor","content":" Substrait definition  Rounds a number down to its closest integer.  Its output type will always be an integer, if a non numeric type is passed in, the function will return null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#sql-usage-1","content":" SELECT floor(column1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Round​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#round","content":" Substrait definition  Rounds a number to its closest integer.  Its output type will always be an integer, if a non numeric type is passed in, the function will return null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Rounding Functions","url":"/flowtide/docs/expressions/scalarfunctions/rounding#sql-usage-2","content":" SELECT round(column1) FROM ...  ","version":"Next","tagName":"h3"},{"title":"String Functions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/scalarfunctions/string","content":"","keywords":"","version":"Next"},{"title":"Concat​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#concat","content":" Substrait definition  Concatinates two or more string values together.  This function tries and convert non string values into the string type, example:  Input\tType\tOutput'hello'\tString\t'hello' 13\tInt\t'13' 13.4\tFloat\t'13.4' true\tBool\t'true'  If any argument is null, the return value will always be null.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage","content":" SELECT c1 || ' hello ' || c2 FROM ...   ","version":"Next","tagName":"h3"},{"title":"Lower​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#lower","content":" Substrait definition  Returns the input string in all lowercase characters. If any other type than string is entered, the function will return 'null'.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-1","content":" SELECT lower(c1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Upper​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#upper","content":" Substrait definition  Returns the input string in all uppercase characters. If any other type than string is entered, the function will return 'null'.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-2","content":" SELECT upper(c1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Trim​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#trim","content":" Substrait definition  Remove whitespaces from both sides of a string  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-3","content":" SELECT trim(c1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"LTrim​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#ltrim","content":" Substrait definition  Remove whitespaces from the start of a string  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-4","content":" SELECT ltrim(c1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"RTrim​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#rtrim","content":" Substrait definition  Remove whitespaces from the end of a string  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-5","content":" SELECT rtrim(c1) FROM ...   ","version":"Next","tagName":"h3"},{"title":"To String​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#to-string","content":" No substrait definition exists for this function  Converts different types to a string type.  Example output:  Input\tType\tOutput'hello'\tString\t'hello' 13\tInt\t'13' 13.4\tFloat\t'13.4' true\tBool\t'true'  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"String Functions","url":"/flowtide/docs/expressions/scalarfunctions/string#sql-usage-6","content":" SELECT to_string(c1) FROM ...  ","version":"Next","tagName":"h3"},{"title":"Azure Monitor","type":0,"sectionRef":"#","url":"/flowtide/docs/monitoring/azuremonitor","content":"","keywords":"","version":"Next"},{"title":"Metrics export​","type":1,"pageTitle":"Azure Monitor","url":"/flowtide/docs/monitoring/azuremonitor#metrics-export","content":" To export metrics information, you need to install the following nuget packages:  OpenTelemetry.Extensions.HostingAzure.Monitor.OpenTelemetry.Exporter  Next in your Program.cs add the following code:  builder.Services.AddOpenTelemetry() .WithMetrics(builder =&gt; { builder.AddAzureMonitorMetricExporter(o =&gt; { o.ConnectionString = &quot;{your connection string}&quot;; }); builder.AddView((instrument) =&gt; { return new MetricStreamConfiguration() { Name = $&quot;{instrument.Meter.Name}.{instrument.Name}&quot; }; }); builder.AddMeter(&quot;flowtide.*&quot;); });   Replace {your connection string} with your application insights connection string. This will then start uploading custom metrics to your Application Insights in Azure Monitor.  ","version":"Next","tagName":"h2"},{"title":"Health check export​","type":1,"pageTitle":"Azure Monitor","url":"/flowtide/docs/monitoring/azuremonitor#health-check-export","content":" If you want to publish/export health check information, install the following nuget package:  AspNetCore.HealthChecks.Publisher.ApplicationInsights  Add the following to your Program.cs:  builder.Services.AddHealthChecks() .AddFlowtideCheck() .AddApplicationInsightsPublisher(&quot;{your connection string}&quot;);   Replace {your connection string} with your application insights connection string. You should now see custom events being published to Application Insights with health check information.  ","version":"Next","tagName":"h2"},{"title":"Sample​","type":1,"pageTitle":"Azure Monitor","url":"/flowtide/docs/monitoring/azuremonitor#sample","content":" A sample application exist for both setups in github. ","version":"Next","tagName":"h2"},{"title":"Health checks","type":0,"sectionRef":"#","url":"/flowtide/docs/monitoring/healthchecks","content":"","keywords":"","version":"Next"},{"title":"Statuses​","type":1,"pageTitle":"Health checks","url":"/flowtide/docs/monitoring/healthchecks#statuses","content":" This section describes how the different stream statuses maps to the health check status:  Stream Status\tHealth check status\tDescriptionFailing\tUnhealthy\tStream has crashed Running\tRunning\tOperational Starting\tDegraded\tStarting is only reported when going from stopped -&gt; running Stopped\tUnhealthy\tIf a stream should be stopped, remove it from health check Degraded\tDegraded\tReported if a operator is degraded, such as slow performance ","version":"Next","tagName":"h2"},{"title":"Specialized Expressions","type":0,"sectionRef":"#","url":"/flowtide/docs/expressions/specializedexpressions","content":"","keywords":"","version":"Next"},{"title":"Nested Type Constructor Expressions​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#nested-type-constructor-expressions","content":" ","version":"Next","tagName":"h2"},{"title":"List​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#list","content":" Allows the creation of a list object.  SQL Usage​  SELECT list(col1, col2) FROM ...   ","version":"Next","tagName":"h3"},{"title":"Map​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#map","content":" Allows the creation of a map object type. A map is a typical 'json' object with property names and values. The map function consists of a list of key value pairs.  SQL Usage​  The SQL function expects an even number of arguments, the first argument is the key and the second the value for the first key value pair. The third argument is the second pairs key, etc.  SELECT map('keyvalue', col1) FROM ... SELECT map(col2, col1) FROM ...   The keys will be converted into string. A null value will result in 'null' as the key.  ","version":"Next","tagName":"h3"},{"title":"If Expression​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#if-expression","content":" Substrait definition  An if statement, or in SQL language a case statement.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#sql-usage-2","content":" SELECT CASE WHEN c1 = 'hello' THEN 1 WHEN c1 = 'world' THEN 2 ELSE 3 END FROM ...   ","version":"Next","tagName":"h3"},{"title":"Or List Expression​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#or-list-expression","content":" Substrait definition  Checks if a value is equal to any value in a list. This uses Kleene logic for equality.  ","version":"Next","tagName":"h2"},{"title":"SQL Usage​","type":1,"pageTitle":"Specialized Expressions","url":"/flowtide/docs/expressions/specializedexpressions#sql-usage-3","content":" ... WHERE column1 IN (1, 5, 17)  ","version":"Next","tagName":"h3"},{"title":"Buffer Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/buffer","content":"","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Buffer Operator","url":"/flowtide/docs/operators/buffer#metrics","content":" The Buffer Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not. events\tCounter\tHow many events that the operator outputs. ","version":"Next","tagName":"h2"},{"title":"Aggregate Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/aggregate","content":"","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Aggregate Operator","url":"/flowtide/docs/operators/aggregate#metrics","content":" The Aggregate Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not.  info At this point, an aggregate operator will never be unhealthy. If there is a failure against the state, the stream will instead restart. ","version":"Next","tagName":"h2"},{"title":"Iteration Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/iteration","content":"","keywords":"","version":"Next"},{"title":"Iteration Relation​","type":1,"pageTitle":"Iteration Operator","url":"/flowtide/docs/operators/iteration#iteration-relation","content":" The iteration relation uses ExtensionMultiRel in substrait and is defined as follows in protobuf:  message IterationRelation { string iterationName = 1; }   The first input in ExtensionMultiRel is the loop relation, the second input is input to the iteration itself. The second input is optional.  IterationName exist since there can be multiple nested iterations.  ","version":"Next","tagName":"h2"},{"title":"Iteration Reference Read Relation​","type":1,"pageTitle":"Iteration Operator","url":"/flowtide/docs/operators/iteration#iteration-reference-read-relation","content":" This relation is used to tell where the data from the iteration operator should be sent to inside of the loop. This relation should only be used inside the loop relation.  It is defined by ExtensionLeafRel and has the following message:  message IterationReferenceReadRelation { // Name of the iteration to get data from string iterationName = 1; }   ","version":"Next","tagName":"h2"},{"title":"Implementation​","type":1,"pageTitle":"Iteration Operator","url":"/flowtide/docs/operators/iteration#implementation","content":" The iteration operator differs a bit from the other operators in how it does checkpointing. To make sure a checkpoint contains all processed data before comitting to a checkpoint it follows these steps:  If there is no input to the operator, a dummy read operator is created that only sends checkpoint events.On checkpoint send a LockingEventPrepare to the loop.All operators in loop adds information if they have another dependency that is not yet in checkpoint.If any message was recieved before the iteration operator recieves the LockingEventPrepare message, or a dependency is not in checkpoint, the message is resent.When all conditions above are met, the checkpoint is sent throught the loop.When the operator recieves the checkpoint from the loop, it first sends out watermark information, and then the checkpoint to the rest of the stream.  ","version":"Next","tagName":"h2"},{"title":"Metrics​","type":1,"pageTitle":"Iteration Operator","url":"/flowtide/docs/operators/iteration#metrics","content":" The Iteration Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not.  info At this point, an iteration operator will never be unhealthy. If there is a failure against the state, the stream will instead restart. ","version":"Next","tagName":"h2"},{"title":"Getting started","type":0,"sectionRef":"#","url":"/flowtide/docs/intro","content":"","keywords":"","version":"Next"},{"title":"Creating a plan​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#creating-a-plan","content":" The first step is to create an execution plan, this can be be done with any substrait plan creator. But it is also possible to do it with SQL inside flowtide. This tutorial will only show how to create a plan with SQL.  Add the following to your Program.cs:   var sqlBuilder = new SqlPlanBuilder(); sqlBuilder.Sql(@&quot; CREATE TABLE {sqlserver database name}.{schema name}.{tablename} ( val any ); CREATE TABLE {sqlserver database name}.{schema name}.{othertablename} ( val any ); INSERT INTO {sqlserver database name}.{schema name}.{destinationname} SELECT t.val FROM {sqlserver database name}.{schema name}.{tablename} t LEFT JOIN {sqlserver database name}.{schema name}.{othertablename} o ON t.val = o.val WHERE t.val = 123; &quot;); var plan = sqlBuilder.GetPlan();   Replace all values with that are between { } with your own table names in your SQL Server.  ","version":"Next","tagName":"h2"},{"title":"Setting up a read and write factory​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#setting-up-a-read-and-write-factory","content":" Each stream requires a factory that provides it with source and sink operators. These provide the actual implementation when talking with other sources.  Some examples of sinks and sources are:  MS SQLKafkaPostgres  This example will add a connection for SQL Server:  var factory = new ReadWriteFactory(); // Wildcard that all sources should use the following configuration factory.AddSqlServerSource(&quot;*&quot;, () =&gt; &quot;Server={your server};Database={your database};Trusted_Connection=True;&quot;); // Wildcard that all sinks will use this configuration factory.AddSqlServerSink(&quot;*&quot;, () =&gt; &quot;Server={your server};Database={your database};Trusted_Connection=True;&quot;);   ","version":"Next","tagName":"h2"},{"title":"Running the stream​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#running-the-stream","content":" Finally to run the stream we add the following code:  builder.Services.AddFlowtideStream(b =&gt; { b.AddPlan(plan) .AddReadWriteFactory(factory) .WithStateOptions(new StateManagerOptions() { // This is non persistent storage, use FasterKV persistence storage instead if you want persistent storage PersistentStorage = new FileCachePersistentStorage(new FlowtideDotNet.Storage.FileCacheOptions() { }) }); });   ","version":"Next","tagName":"h2"},{"title":"Persistent storage​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#persistent-storage","content":" The previous example does not use persistent storage, to use persistent storage, you can instead use the FasterKV storage:  PersistentStorage = new FasterKvPersistentStorage(new FasterKVSettings&lt;long, SpanByte&gt;() { RemoveOutdatedCheckpoints = true, MemorySize = 1024 * 1024 * 128, PageSize = 1024 * 1024 * 16, LogDevice = Devices.CreateLogDevice(&quot;./data/persistent/log&quot;), CheckpointDir = &quot;./data/checkpoints&quot; })   The stream will then be persistent between checkpoints.  ","version":"Next","tagName":"h3"},{"title":"Adding the UI​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#adding-the-ui","content":" If you want to add the UI to visualize the progress of the stream, add the following code after &quot;var app = builder.Build();&quot;.  app.UseFlowtideUI(&quot;/stream&quot;);   ","version":"Next","tagName":"h2"},{"title":"Full example​","type":1,"pageTitle":"Getting started","url":"/flowtide/docs/intro#full-example","content":" Here is the full code example to get started:   var builder = WebApplication.CreateBuilder(args); var sqlBuilder = new SqlPlanBuilder(); sqlBuilder.Sql(@&quot; CREATE TABLE {sqlserver database name}.{schema name}.{tablename} ( val any ); CREATE TABLE {sqlserver database name}.{schema name}.{othertablename} ( val any ); INSERT INTO {sqlserver database name}.{schema name}.{destinationname} SELECT t.val FROM {sqlserver database name}.{schema name}.{tablename} t LEFT JOIN {sqlserver database name}.{schema name}.{othertablename} o ON t.val = o.val WHERE t.val = 123; &quot;); var plan = sqlBuilder.GetPlan(); var factory = new ReadWriteFactory(); // Wildcard that all sources should use the following configuration factory.AddSqlServerSource(&quot;*&quot;, () =&gt; &quot;Server={your server};Database={your database};Trusted_Connection=True;&quot;); // Wildcard that all sinks will use this configuration factory.AddSqlServerSink(&quot;*&quot;, () =&gt; &quot;Server={your server};Database={your database};Trusted_Connection=True;&quot;); builder.Services.AddFlowtideStream(b =&gt; { b.AddPlan(plan) .AddReadWriteFactory(factory) .WithStateOptions(new StateManagerOptions() { // This is non persistent storage, use FasterKV persistence storage instead if you want persistent storage PersistentStorage = new FileCachePersistentStorage(new FlowtideDotNet.Storage.FileCacheOptions() { }) }); }); var app = builder.Build(); app.UseFlowtideUI(&quot;/stream&quot;); app.Run();  ","version":"Next","tagName":"h2"},{"title":"Prometheus","type":0,"sectionRef":"#","url":"/flowtide/docs/monitoring/prometheus","content":"","keywords":"","version":"Next"},{"title":"Sample​","type":1,"pageTitle":"Prometheus","url":"/flowtide/docs/monitoring/prometheus#sample","content":" You can find a sample in github to see how it can be setup. ","version":"Next","tagName":"h2"},{"title":"Filter Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/filter","content":"","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Filter Operator","url":"/flowtide/docs/operators/filter#metrics","content":" The Projection Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not.  info At this point, a filter operator will never be unhealthy. ","version":"Next","tagName":"h2"},{"title":"Normalization Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/normalization","content":"","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Normalization Operator","url":"/flowtide/docs/operators/normalization#metrics","content":" The Normalization Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not. events\tCounter\tHow many events that pass through the operator.  info At this point, a normalization operator will never be unhealthy. If there is a failure against the state, the stream will instead restart. ","version":"Next","tagName":"h2"},{"title":"Projection Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/projection","content":"","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Projection Operator","url":"/flowtide/docs/operators/projection#metrics","content":" The Projection Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not. events\tCounter\tHow many events that pass through the operator.  info At this point, a projection operator will never be unhealthy. ","version":"Next","tagName":"h2"},{"title":"Join Operators","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/join","content":"","keywords":"","version":"Next"},{"title":"Merge-Join Operator​","type":1,"pageTitle":"Join Operators","url":"/flowtide/docs/operators/join#merge-join-operator","content":" The merge-join operator is a stateful operator that is implemented by two different B+ trees, one for each input source. The trees are sorted based on the keys used in the equality condition.  ","version":"Next","tagName":"h2"},{"title":"Metrics​","type":1,"pageTitle":"Join Operators","url":"/flowtide/docs/operators/join#metrics","content":" Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not. events\tCounter\tHow many events that pass through the operator.  info At this point, a merge-join operator will never be unhealthy.  ","version":"Next","tagName":"h3"},{"title":"Block-Nested Join Operator​","type":1,"pageTitle":"Join Operators","url":"/flowtide/docs/operators/join#block-nested-join-operator","content":" The block-nested join operator is a stateful operator that is implemented using 2 persistent B+ trees, and two temporary B+ trees. The temporary trees fill up with data until a watermark is recieved in which they it performs the join operations. It does this to reduce the amount of I/O that has to be made when reading through the entire persisted dataset.  ","version":"Next","tagName":"h2"},{"title":"Metrics​","type":1,"pageTitle":"Join Operators","url":"/flowtide/docs/operators/join#metrics-1","content":" Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not.  info At this point, a block-nested join operator will never be unhealthy. If there is a failure against the state, the stream will instead restart. ","version":"Next","tagName":"h3"},{"title":"Set Operator","type":0,"sectionRef":"#","url":"/flowtide/docs/operators/set","content":"","keywords":"","version":"Next"},{"title":"Create Table","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/createtable","content":"Create Table The CREATE TABLE data definition is used to add metadata about a table to the SqlPlanBuilder. Since in SQL, multiple tables might have the same column name, the builder must know what columns exist in which table. Since Flowtide is typeless when defining inputs, it is not required to say a datatype when using create table. Example usage: CREATE TABLE table_name ( column1, column2, column3, .... ); Creating table definitions is not required if you are using table providers.","keywords":"","version":"Next"},{"title":"Metrics​","type":1,"pageTitle":"Set Operator","url":"/flowtide/docs/operators/set#metrics","content":" The Set Operator has the following metrics:  Metric Name\tType\tDescriptionbusy\tGauge\tValue 0-1 on how busy the operator is. backpressure\tGauge\tValue 0-1 on how much backpressure the operator has. health\tGauge\tValue 0 or 1, if the operator is healthy or not. events\tCounter\tHow many events that pass through the operator.  info At this point, a set operator will never be unhealthy. If there is a failure against the state, the stream will instead restart. ","version":"Next","tagName":"h2"},{"title":"Parallelism","type":0,"sectionRef":"#","url":"/flowtide/docs/parallelism","content":"Parallelism warning Parallelism support is still experimental. Some operators support running in parallel. This is done by partitioning the input into an operator. For instance in an aggregate with a grouping. It can partition the data on the grouping values. This can help reduce bottlenecks on certain operators that do complex operations. To run a stream with parallelism enabled, add the following to the FlowtideBuilder: flowtideBuilder // Set an integer number here .SetParallelism(parallelism) ","keywords":"","version":"Next"},{"title":"SQL","type":0,"sectionRef":"#","url":"/flowtide/docs/sql","content":"SQL Flowtide has SQL support which will transform the SQL into a substrait plan which can then be run the engine. To create a plan from SQL, add the following code to your application: var sqlBuilder = new SqlPlanBuilder(); sqlBuilder.Sql(@&quot; CREATE TABLE testtable ( val any ); INSERT INTO output SELECT t.val FROM testtable t &quot;); var plan = sqlBuilder.GetPlan(); info All SQL plans must have a source and a sink, so it must always insert to somewhere. The INSERT INTO denotes which output should leave the stream. You can find more information in the following chapters: 📄️ Table Provider It is possible to add table providers to the SqlPlanBuilder. These providers are called each time the compiler finds the usage of a table. 📄️ Create Table The CREATE TABLE data definition is used to add metadata about a table to the SqlPlanBuilder. 📄️ Create View The create view command allows you to define a reusable sub-plan. 🗃️ Select 1 items 📄️ Insert Into The INSERT INTO statement is used to send data from the stream into a sink. Each stream requires at least one insert into statement to mark which data should be output from the stream. 📄️ Recursion Flowtide also supports recusive queries, such as iterating over a tree structure. This is done with the WITH statement, and works similar as in other databases.","keywords":"","version":"Next"},{"title":"Insert Into","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/insertinto","content":"","keywords":"","version":"Next"},{"title":"Example​","type":1,"pageTitle":"Insert Into","url":"/flowtide/docs/sql/insertinto#example","content":" INSERT INTO outputtable SELECT column1, column2 FROM inputtable  ","version":"Next","tagName":"h2"},{"title":"Select","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/select","content":"Select The select statement allows a user to write the actual query that will fetch data from different connectors and transform it into a destination. Below is how the select statement is written in ANTLR format: SELECT scalar_or_aggregate_expression (',' scalar_or_aggregate_expression)* FROM table_source ((LEFT | INNER)? JOIN table_source ON scalar_expression)* (WHERE scalar_expression)? (GROUP BY scalar_expression)? (HAVING scalar_or_aggregate_expression)? All fields which says expression, can take in expressions found under the Expressions chapter.","keywords":"","version":"Next"},{"title":"Union","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/select/union","content":"Union The UNION operator concatenates results from one or several SELECT statements. select_stament UNION ALL select_stament Only union all is supported at this time.","keywords":"","version":"Next"},{"title":"Recursion","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/recursion","content":"Recursion Flowtide also supports recusive queries, such as iterating over a tree structure. This is done with the WITH statement, and works similar as in other databases. Example: with user_manager_cte AS ( SELECT userKey, firstName, lastName, managerKey, null as ManagerFirstName, 1 as level FROM users WHERE managerKey is null UNION ALL SELECT u.userKey, u.firstName, u.lastName, u.managerKey, umc.firstName as ManagerFirstName, level + 1 as level FROM users u INNER JOIN user_manager_cte umc ON umc.userKey = u.managerKey ) INSERT INTO output SELECT userKey, firstName, lastName, managerKey, ManagerFirstName, level FROM user_manager_cte ","keywords":"","version":"Next"},{"title":"Create View","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/createview","content":"","keywords":"","version":"Next"},{"title":"Buffered view​","type":1,"pageTitle":"Create View","url":"/flowtide/docs/sql/createview#buffered-view","content":" It is possible to create a buffered view. It is a view that collects all the output from the view in to temporary storage and waits for a watermark.  This can reduce the output from the view in situations where data is updated regularly but gives the same output value. One example is when a column value is based on gettimestamp such as gettimestamp() &gt; date which will give the same output the majority of the time. The buffered view will then only give out the changed rows, and can reduce computational load in the result of the stream.  It adds a buffer operator at the end of the view.  Example:  CREATE VIEW buffered WITH (BUFFERED = true) AS SELECT CASE WHEN orderdate &lt; gettimestamp() THEN true ELSE false END as active FROM orders;  ","version":"Next","tagName":"h2"},{"title":"Table Provider","type":0,"sectionRef":"#","url":"/flowtide/docs/sql/tableprovider","content":"","keywords":"","version":"Next"},{"title":"Registering a table provider​","type":1,"pageTitle":"Table Provider","url":"/flowtide/docs/sql/tableprovider#registering-a-table-provider","content":" You register a table provider on the SqlPlanBuilder by calling the AddTableProvider method:  var sqlBuilder = new SqlPlanBuilder(); sqlBuilder.AddTableProvider(new MyCustomProvider());   Some connectors, such as SQL Server connector might already come with a provider, a connector usually add an extension method to add its provider. Example on how SQL Server connector provider is added:  sqlBuilder.AddSqlServerProvider(() =&gt; connectionString);  ","version":"Next","tagName":"h2"},{"title":"State Persistence","type":0,"sectionRef":"#","url":"/flowtide/docs/statepersistence","content":"","keywords":"","version":"Next"},{"title":"FasterKV storage​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#fasterkv-storage","content":" FasterKV is persistent key value store built by Microsoft. It is the only storage solution available for Flowtide that will persist data between runs. FasterKV is highly configurable, and how you configure it will affect the performance of your stream.  To configure your stream to use FasterKV storage, add the following to the builder:  builder .WithStateOptions(() =&gt; new StateManagerOptions() { PersistentStorage = new FasterKvPersistentStorage(new FasterKVSettings&lt;long, SpanByte&gt;() { // Set the fasterKV configuration here ... }) });   ","version":"Next","tagName":"h2"},{"title":"Useful configuration options​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#useful-configuration-options","content":" Property\tDescriptionLogDevice\tThe log device that will write to storage MemorySize\tHow much memory FasterKV can use PageSize\thow large a page is CheckpointDir\tWhere checkpoints should be stored CheckpointManager\tCheckpoint manager, useful if using Azure Storage.  ","version":"Next","tagName":"h3"},{"title":"Storing to disk​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#storing-to-disk","content":" This is an example of a configuration to store to a disk.  var baseDirectory = &quot;/persistence/&quot; builder.WithStateOptions(() =&gt; new StateManagerOptions() { // Set cache page count to reduce the memory usage CachePageCount = 10000, PersistentStorage = new FasterKvPersistentStorage(new FasterKVSettings&lt;long, SpanByte&gt;() { // Checkpoint directory CheckpointDir = $&quot;{baseDirectory}/checkpoints&quot;, // A local file log device LogDevice = Devices.CreateLogDevice($&quot;{baseDirectory}/log&quot;), // Redice memory usage of fasterKV, to limit memory usage MemorySize = 1024L * 1024L * 64, // Page size PageSize = 1024 * 1024 * 16, }), TemporaryStorageOptions = new FileCacheOptions() { // Path where the temporary cache is stored DirectoryPath = $&quot;./temp&quot; } })   ","version":"Next","tagName":"h3"},{"title":"Storing to Azure Storage​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#storing-to-azure-storage","content":" Storing the data in an Azure Storage requires a bit more configuration, especially a checkpoint manager.  // Create azure storage device var log = new AzureStorageDevice(STORAGE_STRING, BASE_CONTAINER, &quot;&quot;, &quot;hlog.log&quot;); // Create azure storage backed checkpoint manager var checkpointManager = new DeviceLogCommitCheckpointManager( new AzureStorageNamedDeviceFactory(STORAGE_STRING), new DefaultCheckpointNamingScheme($&quot;{BASE_CONTAINER}/checkpoints/&quot;)); builder.WithStateOptions(() =&gt; new StateManagerOptions() { // Set cache page count to reduce the memory usage CachePageCount = 10000, PersistentStorage = new FasterKvPersistentStorage(new FasterKVSettings&lt;long, SpanByte&gt;() { CheckpointManager = checkpointManager, LogDevice = log, // Redice memory usage of fasterKV, to limit memory usage MemorySize = 1024L * 1024L * 64, // Page size PageSize = 1024 * 1024 * 16, }), TemporaryStorageOptions = new FileCacheOptions() { // Path where the temporary cache is stored DirectoryPath = $&quot;./temp&quot; } })   ","version":"Next","tagName":"h3"},{"title":"Temporary file cache storage​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#temporary-file-cache-storage","content":" This storage solution is useful when developing or running unit tests on a stream. All data will be cleared between each run, but it will be persisted to local disk to reduce RAM usage and allow you to run streams with alot of data.  The implementation of this is using the same solution as the intermediate file cache solution where modified pages are stored between checkpoints.  To configure your stream to use this storage solution, add the following to the stream builder:  builder .WithStateOptions(() =&gt; new StateManagerOptions() { // This is non persistent storage, use FasterKV persistence storage instead if you want persistent storage PersistentStorage = new FileCachePersistentStorage(new FlowtideDotNet.Storage.FileCacheOptions() { DirectoryPath = &quot;./tmp&quot; }) });   ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#configuration","content":" Property\tDefault value\tDescriptionDirectoryPath\t./data/tempFiles\tPath where the files will be stored  ","version":"Next","tagName":"h3"},{"title":"Storage solution​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#storage-solution","content":" The stream storage is built on a three tier architecture, there is the in memory cache, the local disk modified page cache, and the persistent data.  A data page is fetched using the following logic:    ","version":"Next","tagName":"h2"},{"title":"Compression​","type":1,"pageTitle":"State Persistence","url":"/flowtide/docs/statepersistence#compression","content":" It is possible to compress pages in the state. This is done by providing two functions to state serialize options, a compress function and a decompress function.  Example using ZLib compression:  builder.WithStateOptions(() =&gt; new StateManagerOptions() { ... SerializeOptions = new StateSerializeOptions() { CompressFunc = (stream) =&gt; { return new System.IO.Compression.ZLibStream(stream, CompressionMode.Compress); }, DecompressFunc = (stream) =&gt; { return new System.IO.Compression.ZLibStream(stream, CompressionMode.Decompress); } } })  ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}