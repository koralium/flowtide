"use strict";(self.webpackChunkflowtide=self.webpackChunkflowtide||[]).push([[8379],{4055:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"release-0-12-0","metadata":{"permalink":"/flowtide/blog/release-0-12-0","editUrl":"https://github.com/koralium/flowtide/tree/main/docs/blog/2025-01-24-release-0-12-0/index.md","source":"@site/blog/2025-01-24-release-0-12-0/index.md","title":"Release 0.12.0","description":"Major changes","date":"2025-01-24T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/flowtide/blog/tags/release"}],"readingTime":0.865,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"release-0-12-0","title":"Release 0.12.0","tags":["release"]},"unlisted":false,"nextItem":{"title":"Release 0.11.0","permalink":"/flowtide/blog/release-0-11-0"}},"content":"## Major changes\\n\\n### All Processing Operators Updated to Column-Based Events\\n\\nAll processing operators now use the column-based event format, leading to better performance. \\nHowever, some sources and sinks for connectors still use the row-based event format. \\nAdditionally, a few functions continue to rely on the row-based event format.\\n\\n### MongoDB Source Support\\n\\nThis release adds support to read data from MongoDB, this includes using \\nMongoDBs change stream to directly react on data changes.\\n\\n### SQL Server Support for Stream State Persistence\\n\\nYou can now store the stream state in SQL Server. For setup instructions, refer to the documentation:\\nhttps://koralium.github.io/flowtide/docs/statepersistence#sql-server-storage\\n\\n### Timestamp with Time Zone Data Type\\n\\nA new data type for timestamps has been added. \\nThis ensures that connectors can correctly use the appropriate data type, especially when writing. \\nFor example, writing to MongoDB now uses the BSON Date type.\\n\\n\\n## Minor Changes\\n\\n### Virtual Table Support\\n\\nStatic data selection is now supported. Example usage:\\n\\n```\\nINSERT INTO output \\nSELECT * FROM \\n(\\n  VALUES \\n  (1, \'a\'),\\n  (2, \'b\'),\\n  (3, \'c\')\\n)\\n```"},{"id":"release-0-11-0","metadata":{"permalink":"/flowtide/blog/release-0-11-0","editUrl":"https://github.com/koralium/flowtide/tree/main/docs/blog/2024-11-14-release-0-11-0/index.md","source":"@site/blog/2024-11-14-release-0-11-0/index.md","title":"Release 0.11.0","description":"Major Changes","date":"2024-11-14T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/flowtide/blog/tags/release"}],"readingTime":2.78,"hasTruncateMarker":false,"authors":[],"frontMatter":{"slug":"release-0-11-0","title":"Release 0.11.0","tags":["release"]},"unlisted":false,"prevItem":{"title":"Release 0.12.0","permalink":"/flowtide/blog/release-0-12-0"}},"content":"## Major Changes\\n\\n### Column-Based Event Format\\n\\nMost operators have transitioned from treating events as rows with flexbuffer to a column-based format following the Apache Arrow specification. This change has led to significant performance improvements, especially in the merge join and aggregation operators. Transitioning from row-based to column-based events involved a major rewrite of core components, and some operators still use the row-based format, which will be updated in the future.\\n\\nNot all expressions have been converted to work with column data yet. However, the solution currently handles conversions between formats to maintain backward compatibility. Frequent conversions may result in performance decreases.\\n\\nThe shift to a column format also introduced the use of unmanaged memory for new data structures, for the following reasons:\\n\\n* 64-byte aligned memory addresses for optimal SIMD/AVX operations.\\n* Immediate memory return when a page is removed from the LRU cache, instead of waiting for the next garbage collection cycle.\\n\\nWith unmanaged memory, it is now possible to track memory allocation by different operators, providing better insight into memory usage in your stream.\\n\\n### B+ Tree Splitting by Byte Size\\n\\nPreviously, the B+ tree determined page sizes based on the number of elements, splitting pages into two equal parts when the max size (e.g., 128 elements) was reached. While this worked for streams with uniform element sizes, it led to size discrepancies in other cases, affecting serialization time and slowing down the stream.\\n\\nThis update introduces page splitting based on byte size, with a default page size of 32KB, ensuring more consistent and predictable page sizes.\\n\\n### Initial SQL Type Validation\\n\\nThis release contains the beginning of type validation when creating a Substrait plan using SQL. Currently, only SQL Server provides specific type metadata, while sources like Kafka continue to designate columns as \'any\' due to varying payload types.\\n\\nThe new validation feature raises exceptions for type mismatches, such as when a boolean column is compared to an integer (e.g., boolColumn = 1). This helps inform users transitioning from SQL Server that bit columns are treated as boolean in Flowtide.\\n\\n### New UI\\n\\n![new UI](./flowtidenewui.png)\\n\\nA new UI has been developed, featuring an integrated time series database that enables developers to monitor stream behavior over time. This database\u2019s API aligns with Prometheus standards, allowing for custom queries to investigate potential issues.\\n\\nThe UI retrieves all data through the Prometheus API endpoint, enabling future deployment as a standalone tool connected to a Prometheus server.\\n\\n## Minor Changes\\n\\n### Congestion Control Based on Cache Misses\\n\\nFlowtide processes data in small batches, typically 1-100 events. While this approach works well with in-memory data, cache misses that require persistent storage access can create bottlenecks. This is particularly problematic with multiple chained joins, where sequential data fetching can delay processing.\\n\\nTo address this, the join operator now monitors cache misses during a batch and, when a threshold is reached, splits the processed events and forwards them to the next operator. This change allows operators to access persistent storage in parallel, easing congestion.\\n\\n### Reduce the amount of pages written to persistent storage\\n\\nPreviously, all B+ tree metadata was written to persistent storage at every checkpoint, including root page IDs. In streams with numerous operators, this led to unnecessary writes.\\n\\nNow, metadata is only written if changes have occurred, reducing the number of writes and improving storage efficiency."}]}}')}}]);